{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA24onYVZEDnNGginysA3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjcarney/PyTorch/blob/main/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wMtf-_bFEz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b444256e-e803-4a80-a285-15663f82fde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "Feature batch: torch.Size([64, 1, 28, 28])\n",
            "Labels batch: torch.Size([64])\n",
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: <built-in method size of Parameter object at 0x7825300047c0> | Values: tensor([[-0.0242, -0.0272,  0.0275,  ..., -0.0351, -0.0192,  0.0151],\n",
            "        [-0.0049, -0.0342,  0.0184,  ...,  0.0083,  0.0060,  0.0203]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: <built-in method size of Parameter object at 0x782533c31580> | Values: tensor([-0.0322, -0.0026], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: <built-in method size of Parameter object at 0x78252fe6df80> | Values: tensor([[-0.0188, -0.0123, -0.0050,  ..., -0.0424, -0.0173, -0.0154],\n",
            "        [-0.0344, -0.0180, -0.0039,  ...,  0.0255, -0.0039, -0.0133]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: <built-in method size of Parameter object at 0x78252ff2a520> | Values: tensor([0.0440, 0.0297], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: <built-in method size of Parameter object at 0x78252ff28ae0> | Values: tensor([[-0.0293,  0.0349, -0.0131,  ..., -0.0284, -0.0329,  0.0403],\n",
            "        [-0.0295, -0.0330,  0.0340,  ...,  0.0127, -0.0272, -0.0095]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: <built-in method size of Parameter object at 0x782530047790> | Values: tensor([0.0428, 0.0201], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision.io import read_image\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transformation = target_transformation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    return image, label\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(\"Feature batch: \" + str(train_features.size()))\n",
        "print(\"Labels batch: \" + str(train_labels.size()))\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "#plt.imshow(img, cmap=\"gray\")\n",
        "#plt.show()\n",
        "#print(\"Label: \" + str(label))\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10,dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")\n",
        "\n",
        "target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10),)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear_relu_stack(x)\n",
        "      return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "\n",
        "\"\"\"\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "test_image = torch.rand(3,28,28)\n",
        "print(test_image.size())\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(test_image)\n",
        "print(flat_image.size())\n",
        "\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())\n",
        "\n",
        "print(f\"Before ReLU: {hidden1} \\n\\n\")\n",
        "hidden1 = nn.ReLU() (hidden1)\n",
        "print(f\"Afer ReLU:  {hidden1}\")\n",
        "\"\"\"\n",
        "\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "logits = seq_modules(input_image)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "\n",
        "print(f\"Model structure: {model} \\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  print(f\"Layer: {name} | Size: {param.size} | Values: {param[:2]} \\n\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}